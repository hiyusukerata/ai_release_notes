#!/usr/bin/env python
# coding: utf-8

import os
import pickle
import sys
import time
from googleapiclient.discovery import build
from google.auth.transport.requests import Request
from requests.exceptions import RequestException
import requests
from bs4 import BeautifulSoup

# ==========================
# Google Sheets & èªè¨¼è¨­å®š
# ==========================
SCOPES = ['https://www.googleapis.com/auth/spreadsheets']
TOKEN_PICKLE_FILE = 'token.pickle'
SPREADSHEET_ID = "1EVf63WG2LVToyyYCV0_G8Y4AAibfmydAu4xHseisyKA" 
RELEASE_SHEET = "OpenAI" 
URL = "https://help.openai.com/en/articles/6825453-chatgpt-release-notes"

def get_credentials():
    creds = None
    if os.path.exists(TOKEN_PICKLE_FILE):
        with open(TOKEN_PICKLE_FILE, 'rb') as f:
            creds = pickle.load(f)
            
    if not creds or not creds.valid:
        if creds and creds.expired and creds.refresh_token:
            creds.refresh(Request())
        else:
            print("âŒ OAuth ãƒˆãƒ¼ã‚¯ãƒ³ãŒç„¡åŠ¹ã§ã™ã€‚token.pickleã‚’å†å–å¾—ã—ã¦ãã ã•ã„ã€‚")
            sys.exit(1)
    return creds

def write_to_b2(text_content):
    try:
        creds = get_credentials()
        service = build('sheets', 'v4', credentials=creds)
        sheet = service.spreadsheets()
        
        body = {'values': [[text_content]]}
        sheet.values().update(
            spreadsheetId=SPREADSHEET_ID,
            range=f"{RELEASE_SHEET}!B2",
            valueInputOption="USER_ENTERED",
            body=body
        ).execute()
        print(f"âœ… ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã® {RELEASE_SHEET}!B2 ã«è»¢è¨˜å®Œäº†ã€‚")
    except Exception as e:
        print(f"âš ï¸ æ›¸ãè¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

# ==========================
# ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–¢æ•° (403å¯¾ç­–ç‰ˆ)
# ==========================
def extract_second_h1_content(url):
    print(f"ğŸ” {url} ã‹ã‚‰æŠ½å‡ºä¸­...")
    
    # ãƒ–ãƒ©ã‚¦ã‚¶ã«ãªã‚Šã™ã¾ã™ãŸã‚ã®ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’å¼·åŒ–
    headers = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',
        'Accept-Language': 'ja,en-US;q=0.9,en;q=0.8',
        'Cache-Control': 'max-age=0',
        'Connection': 'keep-alive',
    }
    
    try:
        session = requests.Session()
        response = session.get(url, headers=headers, timeout=15)
        response.raise_for_status() 
    except RequestException as e:
        print(f"âŒ ã‚¢ã‚¯ã‚»ã‚¹å¤±æ•—: {e}")
        # ã‚‚ã—403ãŒå‡ºã‚‹å ´åˆã€ã‚µã‚¤ãƒˆå´ãŒãƒœãƒƒãƒˆå¯¾ç­–ã‚’ã•ã‚‰ã«å¼·åŒ–ã—ãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™
        return ""

    soup = BeautifulSoup(response.content, 'html.parser')
    
    # å®Ÿéš›ã®ãƒšãƒ¼ã‚¸æ§‹é€ ã«åˆã‚ã›ã¦ h1 ã¾ãŸã¯è¨˜äº‹å†…ã®æ—¥ä»˜ã‚¯ãƒ©ã‚¹ã‚’æ¢ã™
    # OpenAIã®ãƒ˜ãƒ«ãƒ—è¨˜äº‹ã¯æ§‹é€ ãŒå¤‰ã‚ã‚‹ã“ã¨ãŒã‚ã‚‹ãŸã‚ã€h1ã‚’å†å–å¾—
    h1_elements = soup.find_all('h1')
    
    if len(h1_elements) < 2:
        print(f"âš ï¸ h1ãŒä¸è¶³ã—ã¦ã„ã¾ã™ï¼ˆæ¤œå‡ºæ•°: {len(h1_elements)}ï¼‰ã€‚æ§‹é€ ãŒå¤‰ã‚ã£ãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
        return ""
    
    target_h1 = h1_elements[1] 
    content_parts = []
    content_parts.append(f"ã€{target_h1.get_text(strip=True)}ã€‘")
    
    sibling = target_h1.next_sibling
    while sibling:
        if sibling.name == 'h1':
            break
        if sibling.name:
            text = sibling.get_text(separator='\n', strip=True)
            if text:
                content_parts.append(text)
        sibling = sibling.next_sibling
    
    return '\n\n'.join(content_parts)

if __name__ == "__main__":
    extracted_text = extract_second_h1_content(URL)
    if extracted_text:
        write_to_b2(extracted_text)
    else:
        print("æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
